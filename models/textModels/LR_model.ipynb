{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14033e55-d67d-47d7-b0d2-ed1307e720d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b751166-f4fa-44c0-979e-6a525d0784db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = pd.read_csv(\"all_texts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81a685e-cfa6-4f5b-b719-d9499344d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(all_texts['text'], all_texts['result'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c499ce79-ef94-4046-b3f0-2912f9dcb52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data into numerical vectors using TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "train_texts_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
    "test_texts_tfidf = tfidf_vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b646bf76-1dd3-42ba-b899-7a8746f1ba4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train Logistic Regression Classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(train_texts_tfidf, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e546adb-cd6a-498f-b4ac-5e5f46313e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9164777777777777\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     44901\n",
      "           1       0.91      0.92      0.92     45099\n",
      "\n",
      "    accuracy                           0.92     90000\n",
      "   macro avg       0.92      0.92      0.92     90000\n",
      "weighted avg       0.92      0.92      0.92     90000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate\n",
    "lr_predictions = lr_classifier.predict(test_texts_tfidf)\n",
    "lr_accuracy = accuracy_score(test_labels, lr_predictions)\n",
    "lr_report = classification_report(test_labels, lr_predictions)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n",
    "print(\"Logistic Regression Classification Report:\\n\", lr_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820955ff-1ef6-485b-9f08-8697aec46f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained classifier to a file\n",
    "#joblib.dump(lr_classifier, 'LR_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c58cd22-6aee-46ee-aac7-e729d0abe65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model later\n",
    "loaded_classifier = joblib.load('LR_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe667b6-99c2-4faf-92d3-466a0c27b4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "random_text = \"Once in Berlin, when the big war was happening, there was this secret agent, let's call them Shadow. Shadow really wanted to stop Hitler. They sneaked around, found friends, and learned secret codes. One night, Shadow got close to Hitler's place with a vial of poison in a fancy book. They were ready, but then lots of noise made them stop. They had to leave.But Shadow didn't give up. They made a new plan and kept going. They really wanted to change things and make the bad stuff stop. It was all about being smart, brave, and making sure things were fair.\"\n",
    "random_text_tfidf = tfidf_vectorizer.transform([random_text])\n",
    "result = loaded_classifier.predict(random_text_tfidf)\n",
    "print(\"Prediction:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdde5b6-954e-45a9-a4d5-d9562138acbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
